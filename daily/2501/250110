< 전체적인 프로세스 >
agent, agent-processor 에서 데이터 수집 
-> 삼성일 경우
    -> 바로 s3에 zip, 파일 같은거 저장 -> 이건 백엔드에서 바로 여기서 꺼내가고 있음
-> 그외 
    -> sqs로 전송 -> sqs에서 컨슘해서 red에 저장 -> red에 있는 데이터 꺼냄
                                                -> Mysql같은곳에 저장 -> 화면(엔드포인트)까지 ex) kurve 
                                                -> 필요한 다른 동작


- /api/v1/monitors/products/options/platform-price-histories 분석 결과
red에서 특정 날짜 시간에 해당하는 데이터 수집 -> 
데이터 분류 -> H2 chunk단위로 저장 -> 분류되지 않은 raw 데이터 h2저장 -> 
h2에 저장된 데이터 불러온 후 파싱하여 mysql hourly_product_info_partitioned 테이블 에 저장


< 새로운 작업정의 설정 방법 >
CloudWatch 에 규칙에 들어가서 kurve-product ... 찾고 > 대상 > 편집


15:59,  00  v
16,  01
19,  04  v
20,  05
23,  08  v
00,  09
03,  12  v
04,  13
07,  16  v
08,  17
11,  20  v
12  21


< 배포방법 >
머지 ->  code탭 -> 오른쪽에 Releases 
-> [Draft a new release] 버튼 클릭
-> [choose a tag] 태그 생성 draft(tag명 각 배포 프로젝트명 .... 에다가 버전 1씩 올리기)
-> [generate relaese notes] 버튼 클릭해서 write 에 값 자동으로 채우기 
-> actions 탭에 초록색 동그라미 확인 
-> 원래는 aws 배치 안에 작업정의에서 이미지 바꿔줘야하는데 latest로 되어있으므로 안해줘도 됨
-> 지금 배포한건 12시꺼 돌것이므로 확인 
-> 배포후 작업 한번 돌려보는것까지 해보기




-------------------------DONE-----------------------------------------------------------
배치시 스팟 오류가 발생해서 
애초에 detail 테이블에서 가져올때 distinct로 uid 값 중복 제거후 가져오도록 설정 변경

-------------------------TODO-----------------------------------------------------------
agent, agent-processor 
어떻게 동작하는지 로직 파악 (설명가능하도록)

rds로 인서트할때는 values에 청크로 넣을 수 있는음 그래서 어느정도 속도에 어느정도 나오느지 파악 가능
근데 다이나모는 넣는만큼 비용청구됨 임계값을 초당 몇개 이렇게 넣을 수 있음
초당 10개로 설정했을 때 설정된 임계값 넘어가면 인서트가 안됨
근데 임계값 높게 잡으면 안써도 비용이 나감 (실제 쓰는게 초당 5건인데 인계값이 30이면 25건은 버리게 됨)
초당 비용 파악이 필요 
초당 얼마씩 임계값 설정할지
